{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLcourseweek3.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feLwzXmf7qrh",
        "colab_type": "text"
      },
      "source": [
        "Uploaded csvs to my google drive so when it crashes I don't need to reupload it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGXhAa__B6Iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('classic')\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import sklearn as sk\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#import CSVs\n",
        "# full data set kept killing the enviroment so I limited it\n",
        "trainData = pd.read_csv('train_transaction.csv', nrows=400000)\n",
        "trainId = pd.read_csv('train_identity.csv', nrows=400000)\n",
        "#combine data\n",
        "df = pd.merge(trainData,trainId,how=\"left\",on=\"TransactionID\")\n",
        "\n",
        "#graph Transaction amounts and isFraud\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.ylim(-.1, 1.1)\n",
        "plt.xlim(0, 6000)\n",
        "sns.scatterplot(y='isFraud', x='TransactionAmt', data=df, hue='isFraud', style='isFraud')\n",
        "\n",
        "\n",
        "#define features and target \n",
        "features = ['TransactionAmt'] + ['card1'] + ['card2'] + ['card3'] + ['card5'] +['dist1'] + ['dist2'] + ['id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_13',\n",
        " 'id_14', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_24', 'id_25',\n",
        " 'id_26', 'id_32'] + ['C%d' % number for number in range(1, 14)]\\\n",
        "+ ['D%d' % number for number in range(1, 15)] + ['V%d' % number for number in range(1, 339)]\n",
        "\n",
        "target = 'isFraud'\n",
        "\n",
        "\n",
        "# Now create an X variable (containing the features) and an y variable (containing only the target variable)\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "#address NaN, not sure the best way\n",
        "X.fillna(value=0, inplace=True)\n",
        "\n",
        "print('Nan Addressed')\n",
        "\n",
        "print(X.head())\n",
        "print(X.shape)\n",
        "print('Start Normalizing Data')\n",
        "\n",
        "scaler = preprocessing.StandardScaler(with_mean=True, with_std=True)\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "print('Data Normalized Finished')\n",
        "\n",
        "#rebuild Dataframe after Scaler\n",
        "X = pd.DataFrame(data=X, columns=features)\n",
        "\n",
        "print(X.head())\n",
        "print(X.shape)\n",
        "\n",
        "print('Starting Training')\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "#print(X_train.head())\n",
        "#print(X_test.head())\n",
        "#print(X_train.shape\n",
        "#print(X_test.shape\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "print('Training Complete')\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}